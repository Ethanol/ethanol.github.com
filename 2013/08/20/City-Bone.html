<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">
  <head>
    <meta http-equiv="content-type" content="text/html; charset=utf-8" />
    <meta name="author" content="CubicStone Wei" />
    
    <title>城市骨骼</title>
    
    <link rel="shortcut icon" href="/favicon.ico">
    <link href="/atom.xml" rel="alternate" title="水渍" type="application/atom+xml" />
    <link rel="stylesheet" href="/media/css/style.css">
    <link rel="stylesheet" href="/media/css/github.css">
    <script type="text/javascript" src="/media/js/highlight.pack.js"></script>
    <script type="text/javascript">
      hljs.initHighlightingOnLoad();
    </script>
    <script type="text/javascript">
function mouseOver()
{
document.getElementById('b1').src ="/media/images/logo.png"
}
function mouseOut()
{
document.getElementById('b1').src ="/media/images/logo2.png"
}
</script>
<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-31950738-1']);
  _gaq.push(['_setDomainName', 'multisim.me']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>
  </head>
  <body>
    <div id="container">
      <div id="main" role="main">
        <header>
        <!--<h1><a title="水渍" class="" href="/">水渍</a></h1>-->


  <a href="http://multisim.me" title="水渍" 
onmouseover="mouseOver()" onmouseout="mouseOut()">
<center>
<img alt="水渍" src="/media/images/logo2.png" height="72px" width="128px" id="b1" />
</a>


  <br><br>
</center>
	</a>
        </header>
        <nav>
        <span><a title="archive" class="" href="/archive.html">archive</a></span>

        <span><a title="tags" class="" href="/tags.html">tags</a></span>
        <span><a title="about" class="" href="/about.html">about me</a></span>
        
        <span><a title="blogroll" class="" href="/links.html">links</a></span>
        <span><a title="subscribe me" class="" href="/atom.xml">feed</a></span>
        </nav>
        <article class="content">
  <section class="title">
    <h2>城市骨骼 </h2>
  </section>
  <section class="meta">
  <span class="time">
    <time datetime="2013-08-20">2013-08-20</time>
  </span>
  
  <br />
  <span class="tags">
    {
    
    <a href="/tags.html#城市" title="城市">城市</a>
    
    <a href="/tags.html#北京" title="北京">北京</a>
    
    <a href="/tags.html#Python" title="Python">Python</a>
    
    <a href="/tags.html#Gephi" title="Gephi">Gephi</a>
    
    }
  </span>
  
  </section>
  <section class="post">
  <p>闲来无事利用Python在8684.cn上抓取了公交线路和站点信息，然后用Gephi画出了站点之间的拓扑结构并用了自带的Force Altas算法做了处理，算是假期的无聊消遣。</p>

<p>一些图片的效果意外地好（比如成都的），可以看出城市中公交线路的分布和城市的发展有着千丝万缕的关系。</p>

<hr />

<p>因为是第一次用Python，所以代码写得东倒西歪，效率也很低，不过我是一个懒到透顶的人，扔在那里不处理了。</p>

<p>文件1 抓取8684上的线路信息</p>

<pre><code>#!/usr/bin/python

from bs4 import BeautifulSoup
import urllib2
import re
import time

City='suzhou'
CityNumber=14
UrlStr = "http://"+City+".8684.cn/line"
for i in range(1,CityNumber+1):
    Url = UrlStr+str(i)
    time.sleep(1)
    Req = urllib2.Request(Url)
    resp = urllib2.urlopen(Req)
    respHtml = resp.read()
    soup = BeautifulSoup(respHtml,fromEncoding="GB2312")
    if i==1:
        Found = soup.findAll('a',href=re.compile(r"/x_(?!ff2b3e48)"))
        print i
    elif i!=7: 
        Found = Found + soup.findAll('a',href=re.compile("/x_(?!ff2b3e48)"))
        print i

print "Res=",Found
class Line:
    def __init__(self):
        self.name=''
        self.link=''
LineSet=[]
p1=re.compile(r"&gt;&lt;")
p2=re.compile(r"")
fileH=open('LineUrl.txt','w')
for j in range(0,len(Found)):
    thisStr=str(Found[j])
    thisLine=Line()
    thisLine.name=thisStr.split('&gt;')[1].split('&lt;')[0]
    thisLine.link="http://"+City+".8684.cn"+thisStr[9:20]
    LineSet.append(thisLine)
    print j,LineSet[j].name, LineSet[j].link
    fileH.write(thisLine.name+','+thisLine.link+';')
fileH.close()
</code></pre>

<p>文件2 抓取8684上每条线路的站点信息</p>

<pre><code>#!/usr/bin/python
#coding=utf-8

from bs4 import BeautifulSoup
import urllib2
import re
import time

fileU=open('LineUrl.txt')
urlStr=fileU.read()
fileU.close()
spUrl=urlStr.split(';')
print spUrl
FileS=open('Site.txt','a')
for i in range(0,len(spUrl)-1):
    if(spUrl[i].find('8684.cn/x_ff2b3e48')&gt;=0):
        print 'find!'
        continue
    name=spUrl[i].split(',')[0]
    Url=spUrl[i].split(',')[1]
    Req = urllib2.Request(Url)
    resp = urllib2.urlopen(Req)
    respHtml = resp.read()
    soup = BeautifulSoup(respHtml,fromEncoding="gb18030")
    Found = soup.findAll(attrs={'class':'hc_p8'})

    for j in range(0,len(Found)):
        Res1=str(Found[j]).split(r'&lt;a href=')
        FileS.write(str(i)+'|'+name+'|'+Res1[0].split('&lt;i&gt;')[1].split('：')[0]+'|')
        for k in range(1,len(Res1)):
            FileS.write(Res1[k].split('&gt;')[1].split('&lt;')[0]+'@')
        FileS.write('\n')
    print i, name
    time.sleep(1)
FileS.close()
</code></pre>

<p>文件3 合并处理线路信息的格式</p>

<pre><code>#!/usr/bin/python
#coding=utf-8

import urllib2
import re
import time

fileU=open('Site.txt')
urlStr=fileU.read()
fileU.close()
spUrl=urlStr.split('\n')
class line:
    def __init__(self):
        self.id=-1
        self.name=''
        self.station=[]
spLine=[]
for i in range(0,len(spUrl)-1):
    ThisLine=line()
    tempstr=str(spUrl[i]).split('|')
    ThisLine.id=tempstr[0]
    ThisLine.name=tempstr[1]+'|'+tempstr[2]
    ThisLine.station=tempstr[3].split('@')
    print ThisLine.name
    print ThisLine.station[1]
    ThisLine.station.remove('')
    spLine.append(ThisLine)
    print 'spUrl', i
class p_station:
    def __init__(self):
        self.name=''
        self.line=[]
        self.count=0
StationPair=[]
StationSet=[]
for i in range(0,len(spLine)):
    i1=0
    i2=0
    for j in range(0,len(spLine[i].station)-1):
        StationStr=spLine[i].station[j]+'%'+spLine[i].station[j+1]
        if StationStr in StationSet:
            This=StationPair[StationSet.index(StationStr)]
            This.line.append(spLine[i].name)
            This.count+=1
            i1+=1
        else:
            ThisPair=p_station()
            ThisPair.name=StationStr
            ThisPair.line.append(spLine[i].name)
            ThisPair.count+=1
            StationPair.append(ThisPair)
            StationSet.append(StationStr)
            i2+=1
    print 'spLine', i, spLine[i].name, len(StationPair), 'New=',i2,'Added=',i1
fileP=open('StationPair.txt','a')
for i in range(0,len(StationPair)):
    fileP.write(StationPair[i].name+'@'+str(StationPair[i].count)+'@')
    for j in range(0,len(StationPair[i].line)):
        fileP.write(StationPair[i].line[j]+'~')
    fileP.write('\n')
    print 'station', i
fileP.close()
</code></pre>

<p>文件4 将线路信息处理成Gephi的格式</p>

<pre><code>#!/usr/bin/python
#coding=utf-8

import urllib2
import re
import time

fileU=open('StationPair.txt')
PairStr=fileU.read()
fileU.close()
Pair=PairStr.split('\n')
class p_station:
    def __init__(self):
        self.start=''
        self.end=''
        num=0
DoP=[]
for i in range(0,len(Pair)-1):
    newp=p_station()
    newp.num=str(Pair[i]).split('@')[1]
    newp.start=str(Pair[i]).split('@')[0].split('%')[0]
    newp.end=str(Pair[i]).split('@')[0].split('%')[1]
    DoP.append(newp)
fileD=open('DoP.txt','w')
fileD.write('source\ttarget\tweight\n')
for i in range(0,len(DoP)):
    fileD.write(DoP[i].start+'\t'+DoP[i].end+'\t'+DoP[i].num+'\n')
fileD.close()
</code></pre>

<hr />

<p>我知道你们是不会看上面的代码的</p>

<p>贴两张效果图</p>

<p><img src="/media/images/beijing.png" alt="Beijing" /></p>

<p><img src="/media/images/lanzhou.png" alt="Lanzhou" /></p>

<p><img src="/media/images/chengdu.png" alt="Chengdu" /></p>

  </section>
  
  <section class="comment">
  <div id="disqus_thread"></div>
<script type="text/javascript" src="http://s7.addthis.com/js/250/addthis_widget.js#pubid=ra-4f28f11f3c8ba1c7"></script>
<script type="text/javascript">
    var disqus_shortname = 'multisim';
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = 'http://' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">评论系统由<span class="logo-disqus">Disqus</span>提供</a>
  </section>
  
</article>

        <div id="copy">&copy; 2012 CubicStone Wei | powered by jekyll and github | themed by <a href="http://lhzhang.com" title="sext iii">sext iii</a></div>
      </div>
    </div> <!--! end of #container -->
  </body>
</html>
